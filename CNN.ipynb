{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.383721Z",
     "start_time": "2018-07-05T11:57:48.655335Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.399415Z",
     "start_time": "2018-07-05T11:57:51.386077Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(mins):\n",
    "    mins = str(mins)\n",
    "    with open ('data_list_' + mins, 'rb') as fp:\n",
    "        data_list = np.array(pickle.load(fp))\n",
    "        #data_list = np.reshape(data_list, (data_list.shape[0], data_list.shape[1], 1, data_list.shape[2]))\n",
    "        data_list = np.reshape(data_list, (data_list.shape[0], data_list.shape[1], data_list.shape[2], 1))\n",
    "    with open ('label_list_' + mins, 'rb') as fp:\n",
    "        label_list = np.array(pickle.load(fp))\n",
    "\n",
    "    print(data_list.shape)\n",
    "    print(label_list.shape)\n",
    "    \n",
    "    return data_list, label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.409998Z",
     "start_time": "2018-07-05T11:57:51.402038Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.418163Z",
     "start_time": "2018-07-05T11:57:51.412228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.cast(K.greater(K.clip(y_true * y_pred, 0, 1), 0.20), 'float32'))\n",
    "    pred_positives = K.sum(K.cast(K.greater(K.clip(y_pred, 0, 1), 0.20), 'float32'))\n",
    "\n",
    "    precision = true_positives / (pred_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-measure function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.424970Z",
     "start_time": "2018-07-05T11:57:51.420266Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_measure(y_true, y_pred):\n",
    "    p_val = precision(y_true, y_pred)\n",
    "    r_val = recall(y_true, y_pred)\n",
    "    f_val = 2*p_val*r_val / (p_val + r_val)\n",
    "\n",
    "    return f_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T05:35:08.670227Z",
     "start_time": "2018-07-30T05:35:08.664123Z"
    }
   },
   "source": [
    "# Building module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:51.453388Z",
     "start_time": "2018-07-05T11:57:51.427206Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(batch_input_shape=(None, 10, 38, 1),\n",
    "                            filters=32,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=1,\n",
    "                            padding='valid',\n",
    "                            data_format='channels_last',\n",
    "                            activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=2,\n",
    "                           padding='valid',\n",
    "                           data_format='channels_last'))\n",
    "    \n",
    "    ##model.add(Dropout(0.7))\n",
    "    model.add(Convolution2D(filters=64,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides=1,\n",
    "                            padding='valid',\n",
    "                            data_format='channels_last',\n",
    "                            activation='relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=3,\n",
    "                           padding='valid',\n",
    "                           data_format='channels_last'))\n",
    "    \n",
    "    #model.add(Dropout(0.7))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(4,\n",
    "                    activation='sigmoid'))\n",
    "\n",
    "    adam = Adam(0.001)\n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc', precision, recall, f_measure])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and Spliting training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:57.013446Z",
     "start_time": "2018-07-05T11:57:51.455444Z"
    }
   },
   "outputs": [],
   "source": [
    "history_list = []\n",
    "train_size_rate = 0.9\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "model = create_model()\n",
    "data_list, label_list = get_data('10_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:57:57.157521Z",
     "start_time": "2018-07-05T11:57:57.015302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(data_list, label_list, train_size=train_size_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:08:29.266804Z",
     "start_time": "2018-07-05T11:57:57.159246Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, train_label,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(test_data, test_label),\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T05:43:12.867092Z",
     "start_time": "2018-07-30T05:43:12.863123Z"
    }
   },
   "source": [
    "# Test testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_list, test_label_list = get_data('10_10_test')\n",
    "model.evaluate(test_data_list, test_label_list, batch_size=32, verbose=1, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:08:29.269014Z",
     "start_time": "2018-07-05T11:57:48.644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def plot_filters(layer, x, y):\n",
    "    filters = model.layers[layer].get_weights()[0][:,:,:,:]\n",
    "    fig = plt.figure()\n",
    "    for j in range(len(filters)):\n",
    "        ax = fig.add_subplot(y, x, j+1)\n",
    "        ax.matshow(filters[j][0], cmap = matplotlib.cm.binary)\n",
    "        plt.xticks(np.arrary([]))\n",
    "        plt.yticks(np.arrary([]))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:08:29.270443Z",
     "start_time": "2018-07-05T11:57:48.644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred = model.predict_proba(test_data).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_label.ravel(), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:08:29.272563Z",
     "start_time": "2018-07-05T11:57:48.647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T12:08:29.274144Z",
     "start_time": "2018-07-05T11:57:48.648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
